## Task 2 (Done)

ðŸ“š Trigram Language Model â€” ML Intern Assignment

This project implements a Trigram (N=3) Language Model from scratch.
It includes text cleaning, rare-word handling (<UNK>), trigram probability estimation, and probabilistic text generation.

The project structure:

```
ml-assignment/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ example_corpus.txt
â”‚   â””â”€â”€ large_corpus.txt        (optional â€“ Gutenberg book)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ngram_model.py
â”‚   â”œâ”€â”€ generate.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â””â”€â”€ clean_corpus.py
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_ngram.py
â”‚   â””â”€â”€ conftest.py
â”‚
â””â”€â”€ evaluation.md
```

How to Run the Project:

1. Train & Generate Text (using the example corpus)

From project root:

```
python -m src.generate
```

2. Running Tests

To verify the model:

```
pytest -q
```

You should see:

```
3 passed
```

## Task 2 â€” Scaled Dot-Product Attention (Also Done)

How to Run Task 2

From repo root:

```
cd task2
python demo.py
```

